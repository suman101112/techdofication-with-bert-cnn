{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "path_list_train = glob(\"OneDrive_1_11-1-2020/*/*train*.tsv\")\n",
    "path_list_dev = glob(\"OneDrive_1_11-1-2020/*/*dev*.tsv\")\n",
    "\n",
    "#print(path_list_train)\n",
    "#print(path_list_dev)\n",
    "#print(len(path_list_dev))\n",
    "\n",
    "i=len(path_list_train)-1\n",
    "\n",
    "file_train = path_list_train[i]\n",
    "file_dev = path_list_dev[i]\n",
    "\n",
    "lang = file_train[-6:-4]\n",
    "\n",
    "import csv\n",
    "df_train = pd.read_csv(file_train,sep=\"\\t\",encoding='utf-8',quoting=csv.QUOTE_NONE)\n",
    "df_dev = pd.read_csv(file_dev,sep=\"\\t\",encoding='utf-8',quoting=csv.QUOTE_NONE)\n",
    "\n",
    "df_train = df_train.dropna()\n",
    "df_dev = df_dev.dropna()\n",
    "\n",
    "train_sentences = list(df_train['text'].values)\n",
    "train_labels = list(df_train['label'].values)\n",
    "\n",
    "dev_sentences = list(df_dev['text'].values)\n",
    "dev_labels = list(df_dev['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaTokenizer\n",
    "\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(33, 538),\n",
       " (34, 514),\n",
       " (32, 512),\n",
       " (35, 508),\n",
       " (36, 475),\n",
       " (37, 470),\n",
       " (31, 465),\n",
       " (38, 433),\n",
       " (39, 391),\n",
       " (40, 387),\n",
       " (41, 385),\n",
       " (30, 384),\n",
       " (42, 375),\n",
       " (44, 337),\n",
       " (43, 335),\n",
       " (45, 317),\n",
       " (46, 283),\n",
       " (29, 267),\n",
       " (47, 248),\n",
       " (49, 222),\n",
       " (48, 220),\n",
       " (51, 209),\n",
       " (50, 200),\n",
       " (52, 199),\n",
       " (54, 185),\n",
       " (53, 179),\n",
       " (28, 163),\n",
       " (55, 160),\n",
       " (57, 145),\n",
       " (56, 141),\n",
       " (58, 132),\n",
       " (59, 129),\n",
       " (61, 128),\n",
       " (27, 107),\n",
       " (14, 104),\n",
       " (21, 98),\n",
       " (63, 97),\n",
       " (60, 97),\n",
       " (20, 95),\n",
       " (62, 94),\n",
       " (18, 94),\n",
       " (17, 93),\n",
       " (24, 93),\n",
       " (65, 91),\n",
       " (12, 90),\n",
       " (15, 89),\n",
       " (25, 89),\n",
       " (26, 89),\n",
       " (22, 89),\n",
       " (16, 87),\n",
       " (19, 84),\n",
       " (64, 84),\n",
       " (13, 82),\n",
       " (23, 79),\n",
       " (10, 77),\n",
       " (11, 73),\n",
       " (69, 70),\n",
       " (66, 69),\n",
       " (67, 69),\n",
       " (73, 60),\n",
       " (72, 59),\n",
       " (9, 58),\n",
       " (68, 51),\n",
       " (70, 50),\n",
       " (75, 50),\n",
       " (74, 50),\n",
       " (8, 49),\n",
       " (76, 46),\n",
       " (78, 44),\n",
       " (81, 39),\n",
       " (71, 38),\n",
       " (79, 36),\n",
       " (77, 33),\n",
       " (7, 32),\n",
       " (82, 30),\n",
       " (85, 26),\n",
       " (83, 26),\n",
       " (80, 26),\n",
       " (84, 22),\n",
       " (96, 22),\n",
       " (87, 22),\n",
       " (89, 22),\n",
       " (88, 18),\n",
       " (90, 18),\n",
       " (86, 15),\n",
       " (93, 14),\n",
       " (91, 13),\n",
       " (92, 13),\n",
       " (99, 12),\n",
       " (95, 12),\n",
       " (94, 11),\n",
       " (100, 11),\n",
       " (106, 9),\n",
       " (107, 9),\n",
       " (105, 8),\n",
       " (101, 7),\n",
       " (115, 7),\n",
       " (121, 7),\n",
       " (117, 7),\n",
       " (97, 7)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choose max_length for bert model based on the input length\n",
    "\n",
    "max_length = 0\n",
    "list_len=[]\n",
    "for sentence in train_sentences:\n",
    "    #print(sentence)\n",
    "    length = len(tokenizer.tokenize(sentence))\n",
    "    list_len.append(length)\n",
    "    \n",
    "from collections import Counter\n",
    "Counter(list_len).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "encoded_labels = le.transform(train_labels)\n",
    "encoded_test_labels = le.transform(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  So , the CPU then pick up the data copies the data from the keyboards internal buffer in to the memory right .\n",
      "Token IDs: tensor([     0,   1061,      6,      4,     70,  86039,   7068,  39580,   1257,\n",
      "            70,   2053,  71200,      7,     70,   2053,   1295,     70, 149186,\n",
      "             7,  70796,    373,  18234,     23,     47,     70,  98323,   7108,\n",
      "             6,      5,      2,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1])\n"
     ]
    }
   ],
   "source": [
    "def encoder_generator(sentences,labels):\n",
    "    \n",
    "    sent_index = []\n",
    "    input_ids = []\n",
    "    attention_masks =[]\n",
    "\n",
    "    for index,sent in enumerate(sentences):\n",
    "        \n",
    "        sent_index.append(index)\n",
    "        \n",
    "        encoded_dict = tokenizer.encode_plus(sent,\n",
    "                                             add_special_tokens=True,\n",
    "                                             max_length=64,\n",
    "                                             pad_to_max_length=True,\n",
    "                                             truncation = True,\n",
    "                                             return_attention_mask=True,\n",
    "                                             return_tensors='pt')\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids,dim=0)\n",
    "    attention_masks = torch.cat(attention_masks,dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "    sent_index = torch.tensor(sent_index)\n",
    "\n",
    "    return sent_index,input_ids,attention_masks,labels\n",
    "\n",
    "train_sent_index,train_input_ids,train_attention_masks,train_encoded_label_tensors = encoder_generator(train_sentences,encoded_labels)\n",
    "dev_sent_index,dev_input_ids,dev_attention_masks,dev_encoded_label_tensors = encoder_generator(dev_sentences,encoded_test_labels)\n",
    "print('Original: ', train_sentences[0])\n",
    "print('Token IDs:', train_input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data samples is 13580\n",
      "valid data samples is 1360\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset,random_split\n",
    "\n",
    "train_dataset = TensorDataset(train_input_ids,train_attention_masks,train_encoded_label_tensors)\n",
    "dev_dataset = TensorDataset(dev_input_ids,dev_attention_masks,dev_encoded_label_tensors)\n",
    "\n",
    "\n",
    "print('train data samples is {}'.format(len(train_dataset)))\n",
    "print(\"valid data samples is {}\".format(len(dev_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,RandomSampler,SequentialSampler\n",
    "\n",
    "bs=4\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset,\n",
    "                              sampler=RandomSampler(train_dataset),\n",
    "                              batch_size=bs)\n",
    "valid_data_loader = DataLoader(dev_dataset,\n",
    "                              sampler=RandomSampler(dev_dataset),\n",
    "                              batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaModel\n",
    "\n",
    "xlm_roberta = XLMRobertaModel.from_pretrained('xlm-roberta-base')\n",
    "xlm_roberta = xlm_roberta.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc_input = nn.Linear(embedding_dim,embedding_dim)\n",
    "        \n",
    "        self.conv_0 = nn.Conv1d(in_channels = embedding_dim, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = filter_sizes[0])\n",
    "        \n",
    "        self.conv_1 = nn.Conv1d(in_channels = embedding_dim, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = filter_sizes[1])\n",
    "        \n",
    "        self.conv_2 = nn.Conv1d(in_channels = embedding_dim, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = filter_sizes[2])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, encoded):\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        embedded = self.fc_input(encoded)\n",
    "        #print(embedded.shape)\n",
    "        \n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "        #print(embedded.shape)\n",
    "        \n",
    "        #embedded = [batch size, emb dim, sent len]\n",
    "        \n",
    "        conved_0 = F.relu(self.conv_0(embedded))\n",
    "        conved_1 = F.relu(self.conv_1(embedded))\n",
    "        conved_2 = F.relu(self.conv_2(embedded))\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "        \n",
    "        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n",
    "        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
    "        pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n",
    "        \n",
    "        #pooled_n = [batch size, n_fibatlters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat((pooled_0, pooled_1, pooled_2), dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        result =  self.fc(cat)\n",
    "        \n",
    "        #print(result.shape)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 768\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = len(le.classes_)\n",
    "DROPOUT = 0.1\n",
    "PAD_IDX = tokenizer.pad_token_id\n",
    "\n",
    "cnn = CNN(EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "cnn = cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model_prameters = list(xlm_roberta.parameters())+list(cnn.parameters())\n",
    "\n",
    "optimizer = optim.Adam(model_prameters,lr=2e-5,eps=1e-8)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train():\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    xlm_roberta.train()\n",
    "    cnn.train()\n",
    "    \n",
    "    for batch in tqdm(train_data_loader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        embedded = xlm_roberta(b_input_ids,b_input_mask)[0]\n",
    "        \n",
    "        predictions = cnn(embedded)\n",
    "        #print(predictions.shape)\n",
    "        #print(b_labels.shape)\n",
    "        \n",
    "        loss = criterion(predictions, b_labels)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, b_labels)\n",
    "        #print(acc)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(train_data_loader), epoch_acc / len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predictions_labels(preds,labels):\n",
    "    pred = np.argmax(preds,axis=1).flatten()\n",
    "    label = labels.flatten()\n",
    "    return pred,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score,f1_score\n",
    "def eval():\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    total_predictions = []\n",
    "    total_true = []\n",
    "    \n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "    \n",
    "    xlm_roberta.eval()\n",
    "    cnn.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in tqdm(valid_data_loader):\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            embedded = xlm_roberta(b_input_ids,b_input_mask)[0]\n",
    "            predictions = cnn(embedded)\n",
    "            #print(predictions.shape)\n",
    "            #print(b_labels.shape)\n",
    "\n",
    "            loss = criterion(predictions, b_labels)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            predictions = predictions.detach().cpu().numpy()\n",
    "\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "            pred,true = predictions_labels(predictions,label_ids)\n",
    "        \n",
    "            all_pred_labels.extend(pred)\n",
    "            all_true_labels.extend(true)\n",
    "\n",
    "    print(classification_report(all_pred_labels,all_true_labels))\n",
    "    avg_val_accuracy = accuracy_score(all_pred_labels,all_true_labels)\n",
    "    macro_f1_score = f1_score(all_pred_labels,all_true_labels,average='macro')\n",
    "    \n",
    "    avg_val_loss = epoch_loss/len(valid_data_loader)\n",
    "\n",
    "    print(\"accuracy = {0:.2f}\".format(avg_val_accuracy))\n",
    "            \n",
    "    return avg_val_loss,avg_val_accuracy,macro_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3395/3395 [09:16<00:00,  6.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:06<00:00, 48.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.71      0.65       170\n",
      "           1       0.58      0.66      0.62       160\n",
      "           2       0.76      0.71      0.73       192\n",
      "           3       0.79      0.79      0.79       199\n",
      "           4       0.72      0.73      0.73       197\n",
      "           5       0.82      0.74      0.78       221\n",
      "           6       0.82      0.74      0.78       221\n",
      "\n",
      "    accuracy                           0.73      1360\n",
      "   macro avg       0.73      0.73      0.72      1360\n",
      "weighted avg       0.74      0.73      0.73      1360\n",
      "\n",
      "accuracy = 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suman\\Miniconda3\\envs\\py3_env\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "  0%|                                                                                 | 1/3395 [00:00<08:48,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch: 01 | Epoch Time: 9m 23s\n",
      "\tTrain Loss: 0.847 | Train Acc: 69.41%\n",
      "\t Val. Loss: 0.860 |  Val. Acc: 72.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3395/3395 [09:15<00:00,  6.11it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:07<00:00, 47.32it/s]\n",
      "  0%|                                                                                 | 1/3395 [00:00<08:58,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.76      0.63       143\n",
      "           1       0.57      0.65      0.61       157\n",
      "           2       0.19      0.97      0.32        36\n",
      "           3       0.89      0.57      0.69       314\n",
      "           4       0.87      0.68      0.76       256\n",
      "           5       0.85      0.67      0.75       255\n",
      "           6       0.77      0.77      0.77       199\n",
      "\n",
      "    accuracy                           0.68      1360\n",
      "   macro avg       0.67      0.72      0.65      1360\n",
      "weighted avg       0.77      0.68      0.70      1360\n",
      "\n",
      "accuracy = 0.68\n",
      "Epoch: 02 | Epoch Time: 9m 22s\n",
      "\tTrain Loss: 0.434 | Train Acc: 85.05%\n",
      "\t Val. Loss: 1.039 |  Val. Acc: 67.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3395/3395 [09:12<00:00,  6.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:07<00:00, 48.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75       178\n",
      "           1       0.63      0.69      0.66       163\n",
      "           2       0.83      0.62      0.71       241\n",
      "           3       0.64      0.90      0.75       142\n",
      "           4       0.88      0.76      0.82       229\n",
      "           5       0.82      0.80      0.81       206\n",
      "           6       0.80      0.80      0.80       201\n",
      "\n",
      "    accuracy                           0.76      1360\n",
      "   macro avg       0.76      0.77      0.76      1360\n",
      "weighted avg       0.77      0.76      0.76      1360\n",
      "\n",
      "accuracy = 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 1/3395 [00:00<09:28,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch: 03 | Epoch Time: 9m 19s\n",
      "\tTrain Loss: 0.265 | Train Acc: 90.98%\n",
      "\t Val. Loss: 0.880 |  Val. Acc: 75.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3395/3395 [09:04<00:00,  6.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:06<00:00, 50.38it/s]\n",
      "  0%|                                                                                 | 1/3395 [00:00<09:45,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71       213\n",
      "           1       0.73      0.54      0.62       244\n",
      "           2       0.68      0.72      0.70       172\n",
      "           3       0.72      0.80      0.76       181\n",
      "           4       0.66      0.86      0.75       153\n",
      "           5       0.73      0.77      0.75       190\n",
      "           6       0.84      0.81      0.83       207\n",
      "\n",
      "    accuracy                           0.73      1360\n",
      "   macro avg       0.73      0.74      0.73      1360\n",
      "weighted avg       0.73      0.73      0.73      1360\n",
      "\n",
      "accuracy = 0.73\n",
      "Epoch: 04 | Epoch Time: 9m 11s\n",
      "\tTrain Loss: 0.200 | Train Acc: 93.42%\n",
      "\t Val. Loss: 0.958 |  Val. Acc: 73.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3395/3395 [09:16<00:00,  6.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:07<00:00, 48.29it/s]\n",
      "  0%|                                                                                 | 1/3395 [00:00<08:54,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.74       188\n",
      "           1       0.54      0.62      0.58       157\n",
      "           2       0.58      0.78      0.67       134\n",
      "           3       0.80      0.75      0.77       213\n",
      "           4       0.67      0.84      0.75       159\n",
      "           5       0.83      0.66      0.74       252\n",
      "           6       0.89      0.69      0.77       257\n",
      "\n",
      "    accuracy                           0.72      1360\n",
      "   macro avg       0.72      0.73      0.72      1360\n",
      "weighted avg       0.74      0.72      0.73      1360\n",
      "\n",
      "accuracy = 0.72\n",
      "Epoch: 05 | Epoch Time: 9m 23s\n",
      "\tTrain Loss: 0.436 | Train Acc: 84.21%\n",
      "\t Val. Loss: 0.979 |  Val. Acc: 72.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3395/3395 [09:12<00:00,  6.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:06<00:00, 48.72it/s]\n",
      "  0%|                                                                                 | 1/3395 [00:00<08:54,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.69       173\n",
      "           1       0.70      0.61      0.65       208\n",
      "           2       0.68      0.67      0.67       182\n",
      "           3       0.79      0.73      0.76       214\n",
      "           4       0.76      0.81      0.78       187\n",
      "           5       0.84      0.79      0.81       214\n",
      "           6       0.80      0.88      0.84       182\n",
      "\n",
      "    accuracy                           0.74      1360\n",
      "   macro avg       0.74      0.75      0.74      1360\n",
      "weighted avg       0.75      0.74      0.74      1360\n",
      "\n",
      "accuracy = 0.74\n",
      "Epoch: 06 | Epoch Time: 9m 19s\n",
      "\tTrain Loss: 0.156 | Train Acc: 94.86%\n",
      "\t Val. Loss: 1.036 |  Val. Acc: 74.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3395/3395 [09:15<00:00,  6.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:06<00:00, 49.41it/s]\n",
      "  0%|                                                                                 | 1/3395 [00:00<09:08,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.62      0.69       250\n",
      "           1       0.59      0.65      0.62       162\n",
      "           2       0.72      0.64      0.67       203\n",
      "           3       0.70      0.76      0.73       184\n",
      "           4       0.80      0.81      0.80       197\n",
      "           5       0.75      0.82      0.78       183\n",
      "           6       0.75      0.83      0.79       181\n",
      "\n",
      "    accuracy                           0.73      1360\n",
      "   macro avg       0.73      0.73      0.73      1360\n",
      "weighted avg       0.73      0.73      0.73      1360\n",
      "\n",
      "accuracy = 0.73\n",
      "Epoch: 07 | Epoch Time: 9m 21s\n",
      "\tTrain Loss: 0.114 | Train Acc: 96.11%\n",
      "\t Val. Loss: 1.117 |  Val. Acc: 72.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3395/3395 [09:16<00:00,  6.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:07<00:00, 45.74it/s]\n",
      "  0%|                                                                                 | 1/3395 [00:00<09:52,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.91      0.69       122\n",
      "           1       0.58      0.66      0.62       159\n",
      "           2       0.80      0.71      0.75       204\n",
      "           3       0.74      0.87      0.80       170\n",
      "           4       0.84      0.79      0.82       214\n",
      "           5       0.93      0.64      0.75       291\n",
      "           6       0.83      0.83      0.83       200\n",
      "\n",
      "    accuracy                           0.76      1360\n",
      "   macro avg       0.75      0.77      0.75      1360\n",
      "weighted avg       0.78      0.76      0.76      1360\n",
      "\n",
      "accuracy = 0.76\n",
      "Epoch: 08 | Epoch Time: 9m 23s\n",
      "\tTrain Loss: 0.082 | Train Acc: 97.32%\n",
      "\t Val. Loss: 1.224 |  Val. Acc: 75.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3395/3395 [09:12<00:00,  6.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:06<00:00, 49.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.83      0.72       156\n",
      "           1       0.65      0.67      0.66       175\n",
      "           2       0.83      0.66      0.74       226\n",
      "           3       0.77      0.83      0.80       186\n",
      "           4       0.80      0.78      0.79       204\n",
      "           5       0.81      0.75      0.78       214\n",
      "           6       0.81      0.82      0.82       199\n",
      "\n",
      "    accuracy                           0.76      1360\n",
      "   macro avg       0.76      0.76      0.76      1360\n",
      "weighted avg       0.77      0.76      0.76      1360\n",
      "\n",
      "accuracy = 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 1/3395 [00:00<09:01,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch: 09 | Epoch Time: 9m 19s\n",
      "\tTrain Loss: 0.102 | Train Acc: 96.76%\n",
      "\t Val. Loss: 0.942 |  Val. Acc: 76.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3395/3395 [09:20<00:00,  6.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:06<00:00, 49.26it/s]\n",
      "  0%|                                                                                 | 1/3395 [00:00<08:51,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.73       171\n",
      "           1       0.60      0.65      0.62       166\n",
      "           2       0.75      0.66      0.70       206\n",
      "           3       0.78      0.79      0.78       197\n",
      "           4       0.81      0.84      0.82       191\n",
      "           5       0.83      0.70      0.76       237\n",
      "           6       0.80      0.83      0.82       192\n",
      "\n",
      "    accuracy                           0.75      1360\n",
      "   macro avg       0.75      0.75      0.75      1360\n",
      "weighted avg       0.76      0.75      0.75      1360\n",
      "\n",
      "accuracy = 0.75\n",
      "Epoch: 10 | Epoch Time: 9m 27s\n",
      "\tTrain Loss: 0.111 | Train Acc: 96.37%\n",
      "\t Val. Loss: 1.193 |  Val. Acc: 75.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3395/3395 [09:08<00:00,  6.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:07<00:00, 47.90it/s]\n",
      "  0%|                                                                                 | 1/3395 [00:00<09:11,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.78      0.68       152\n",
      "           1       0.64      0.63      0.64       185\n",
      "           2       0.72      0.73      0.72       176\n",
      "           3       0.77      0.79      0.78       195\n",
      "           4       0.70      0.85      0.77       165\n",
      "           5       0.82      0.68      0.75       242\n",
      "           6       0.88      0.71      0.79       245\n",
      "\n",
      "    accuracy                           0.73      1360\n",
      "   macro avg       0.73      0.74      0.73      1360\n",
      "weighted avg       0.75      0.73      0.74      1360\n",
      "\n",
      "accuracy = 0.73\n",
      "Epoch: 11 | Epoch Time: 9m 15s\n",
      "\tTrain Loss: 0.080 | Train Acc: 97.41%\n",
      "\t Val. Loss: 1.152 |  Val. Acc: 73.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3395/3395 [09:06<00:00,  6.21it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:06<00:00, 49.55it/s]\n",
      "  0%|                                                                                 | 1/3395 [00:00<09:22,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.73       173\n",
      "           1       0.66      0.64      0.65       186\n",
      "           2       0.62      0.67      0.64       168\n",
      "           3       0.81      0.73      0.77       224\n",
      "           4       0.73      0.83      0.78       177\n",
      "           5       0.81      0.70      0.75       232\n",
      "           6       0.81      0.81      0.81       200\n",
      "\n",
      "    accuracy                           0.74      1360\n",
      "   macro avg       0.73      0.74      0.73      1360\n",
      "weighted avg       0.74      0.74      0.74      1360\n",
      "\n",
      "accuracy = 0.74\n",
      "Epoch: 12 | Epoch Time: 9m 13s\n",
      "\tTrain Loss: 0.084 | Train Acc: 97.22%\n",
      "\t Val. Loss: 1.162 |  Val. Acc: 73.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3395/3395 [09:11<00:00,  6.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:06<00:00, 49.76it/s]\n",
      "  0%|                                                                                 | 1/3395 [00:00<08:58,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.70       152\n",
      "           1       0.76      0.55      0.64       249\n",
      "           2       0.74      0.70      0.72       190\n",
      "           3       0.82      0.81      0.82       202\n",
      "           4       0.79      0.81      0.80       195\n",
      "           5       0.81      0.81      0.81       201\n",
      "           6       0.76      0.88      0.81       171\n",
      "\n",
      "    accuracy                           0.76      1360\n",
      "   macro avg       0.76      0.77      0.76      1360\n",
      "weighted avg       0.76      0.76      0.75      1360\n",
      "\n",
      "accuracy = 0.76\n",
      "Epoch: 13 | Epoch Time: 9m 18s\n",
      "\tTrain Loss: 0.062 | Train Acc: 97.99%\n",
      "\t Val. Loss: 1.404 |  Val. Acc: 75.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3395/3395 [09:11<00:00,  6.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:07<00:00, 48.36it/s]\n",
      "  0%|                                                                                 | 1/3395 [00:00<09:35,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.80      0.71       157\n",
      "           1       0.63      0.66      0.65       173\n",
      "           2       0.60      0.79      0.68       137\n",
      "           3       0.82      0.75      0.79       220\n",
      "           4       0.73      0.89      0.80       164\n",
      "           5       0.85      0.72      0.78       235\n",
      "           6       0.91      0.66      0.77       274\n",
      "\n",
      "    accuracy                           0.74      1360\n",
      "   macro avg       0.74      0.75      0.74      1360\n",
      "weighted avg       0.77      0.74      0.75      1360\n",
      "\n",
      "accuracy = 0.74\n",
      "Epoch: 14 | Epoch Time: 9m 19s\n",
      "\tTrain Loss: 0.063 | Train Acc: 98.03%\n",
      "\t Val. Loss: 1.338 |  Val. Acc: 74.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3395/3395 [09:12<00:00,  6.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:06<00:00, 49.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74       175\n",
      "           1       0.66      0.63      0.65       188\n",
      "           2       0.68      0.71      0.70       173\n",
      "           3       0.73      0.78      0.76       189\n",
      "           4       0.90      0.72      0.80       251\n",
      "           5       0.79      0.83      0.81       191\n",
      "           6       0.82      0.85      0.83       193\n",
      "\n",
      "    accuracy                           0.76      1360\n",
      "   macro avg       0.75      0.76      0.75      1360\n",
      "weighted avg       0.76      0.76      0.76      1360\n",
      "\n",
      "accuracy = 0.76\n",
      "Epoch: 15 | Epoch Time: 9m 19s\n",
      "\tTrain Loss: 0.079 | Train Acc: 97.60%\n",
      "\t Val. Loss: 1.234 |  Val. Acc: 75.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "best_macro_f1 = float('0')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss,train_acc = train()\n",
    "    valid_loss,valid_acc,macro_f1 = eval()\n",
    "    end_time = time.time()\n",
    "    \n",
    "        \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "    if macro_f1 > best_macro_f1:\n",
    "        best_macro_f1 = macro_f1\n",
    "        torch.save(xlm_roberta,'xlmr_cnn_model_part1_'+lang+'task2a.pt')\n",
    "        torch.save(cnn,'xlmr_cnn_model_part2_'+lang+'task2a.pt')\n",
    "        print(\"model saved\")\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xlm_roberta\n",
    "del cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_env",
   "language": "python",
   "name": "py3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
